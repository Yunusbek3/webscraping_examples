{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807e3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Collect car listing URLs from the website.\n",
    "# Steps:\n",
    "# 1. Identify and gather all buttons that contain car listing URLs.\n",
    "# 2. Extract and construct the full URLs from the relevant attributes.\n",
    "# 3. Store each URL in a list for further processing.\n",
    "# Next task: Use the collected URLs to visit each listing and extract detailed information (e.g., car specs, prices, contact details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41b512be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "service = Service()\n",
    "main_driver = webdriver.Chrome(service=service)\n",
    "main_driver.get(\"https://avtoelon.uz/uz/avto/?auto-fuel=1\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "buttons = main_driver.find_elements(By.XPATH, '//button[contains(@class, \"js__advert-button\")]')\n",
    "urls = []\n",
    "\n",
    "# Collect URLs\n",
    "for button in buttons:\n",
    "    partial_url = button.get_attribute('data-url')\n",
    "    url = f\"https://avtoelon.uz{partial_url}\"\n",
    "    urls.append(url)  # Append the URL to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc51b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Page 1 scraped with 20 listings.\n",
      "  Page 2 scraped with 20 listings.\n",
      "  Page 3 scraped with 20 listings.\n",
      "  Page 4 scraped with 20 listings.\n",
      "  Page 5 scraped with 20 listings.\n",
      "  Page 6 scraped with 20 listings.\n",
      "  Page 7 scraped with 20 listings.\n",
      "  Page 8 scraped with 20 listings.\n",
      "  Page 9 scraped with 20 listings.\n",
      "  Page 10 scraped with 20 listings.\n",
      "  Page 11 scraped with 20 listings.\n",
      "  Page 12 scraped with 20 listings.\n",
      "  Page 13 scraped with 20 listings.\n",
      "  Page 14 scraped with 20 listings.\n",
      "  Page 15 scraped with 20 listings.\n",
      "  Page 16 scraped with 20 listings.\n",
      "  Page 17 scraped with 20 listings.\n",
      "  Page 18 scraped with 20 listings.\n",
      "  Page 19 scraped with 20 listings.\n",
      "  Page 20 scraped with 20 listings.\n",
      "  Page 21 scraped with 20 listings.\n",
      "  Page 22 scraped with 20 listings.\n",
      "  Page 23 scraped with 20 listings.\n",
      "  Page 24 scraped with 20 listings.\n",
      "  Page 25 scraped with 20 listings.\n",
      "  Page 26 scraped with 20 listings.\n",
      "  Page 27 scraped with 20 listings.\n",
      "  Page 28 scraped with 20 listings.\n",
      "  Page 29 scraped with 20 listings.\n",
      "  Page 30 scraped with 20 listings.\n",
      "  Page 31 scraped with 20 listings.\n",
      "  Page 32 scraped with 20 listings.\n",
      "  Page 33 scraped with 20 listings.\n",
      "  Page 34 scraped with 20 listings.\n",
      "  Page 35 scraped with 20 listings.\n",
      "  Page 36 scraped with 20 listings.\n",
      "  Page 37 scraped with 20 listings.\n",
      "  Page 38 scraped with 20 listings.\n",
      "  Page 39 scraped with 20 listings.\n",
      "  Page 40 scraped with 20 listings.\n",
      "  Page 41 scraped with 20 listings.\n",
      "  Page 42 scraped with 20 listings.\n",
      "  Page 43 scraped with 20 listings.\n",
      "  Page 44 scraped with 20 listings.\n",
      "  Page 45 scraped with 20 listings.\n",
      "  Page 46 scraped with 20 listings.\n",
      "  Page 47 scraped with 20 listings.\n",
      "  Page 48 scraped with 20 listings.\n",
      "  Page 49 scraped with 20 listings.\n",
      "  Page 50 scraped with 20 listings.\n",
      "  Page 51 scraped with 20 listings.\n",
      "  Page 52 scraped with 20 listings.\n",
      "  Page 53 scraped with 20 listings.\n",
      "  Page 54 scraped with 20 listings.\n",
      "  Page 55 scraped with 20 listings.\n",
      "  Page 56 scraped with 20 listings.\n",
      "  Page 57 scraped with 20 listings.\n",
      "  Page 58 scraped with 20 listings.\n",
      "  Page 59 scraped with 20 listings.\n",
      "  Page 60 scraped with 20 listings.\n",
      "  Page 61 scraped with 20 listings.\n",
      "  Page 62 scraped with 20 listings.\n",
      "  Page 63 scraped with 20 listings.\n",
      "  Page 64 scraped with 20 listings.\n",
      "  Page 65 scraped with 20 listings.\n",
      "  Page 66 scraped with 20 listings.\n",
      "  Page 67 scraped with 20 listings.\n",
      "  Page 68 scraped with 20 listings.\n",
      "  Page 69 scraped with 20 listings.\n",
      "  Page 70 scraped with 20 listings.\n",
      "  Page 71 scraped with 20 listings.\n",
      "  Page 72 scraped with 20 listings.\n",
      "  Page 73 scraped with 20 listings.\n",
      "  Page 74 scraped with 20 listings.\n",
      "  Page 75 scraped with 20 listings.\n",
      "  Page 76 scraped with 20 listings.\n",
      "  Page 77 scraped with 20 listings.\n",
      "  Page 78 scraped with 20 listings.\n",
      "  Page 79 scraped with 20 listings.\n",
      "  Page 80 scraped with 20 listings.\n",
      "  Page 81 scraped with 20 listings.\n",
      "  Page 82 scraped with 20 listings.\n",
      "  Page 83 scraped with 20 listings.\n",
      "  Page 84 scraped with 20 listings.\n",
      "  Page 85 scraped with 20 listings.\n",
      "  Page 86 scraped with 20 listings.\n",
      "  Page 87 scraped with 20 listings.\n",
      "  Page 88 scraped with 20 listings.\n",
      "  Page 89 scraped with 20 listings.\n",
      "  Page 90 scraped with 20 listings.\n",
      "  Page 91 scraped with 20 listings.\n",
      "  Page 92 scraped with 20 listings.\n",
      "  Page 93 scraped with 20 listings.\n",
      "  Page 94 scraped with 20 listings.\n",
      "  Page 95 scraped with 20 listings.\n",
      "  Page 96 scraped with 20 listings.\n",
      "  Page 97 scraped with 20 listings.\n",
      "  Page 98 scraped with 20 listings.\n",
      "  Page 99 scraped with 20 listings.\n",
      "  Page 100 scraped with 20 listings.\n",
      "  Page 101 scraped with 20 listings.\n",
      "  Page 102 scraped with 20 listings.\n",
      "  Page 103 scraped with 20 listings.\n",
      "  Page 104 scraped with 20 listings.\n",
      "  Page 105 scraped with 20 listings.\n",
      "  Page 106 scraped with 20 listings.\n",
      "  Page 107 scraped with 20 listings.\n",
      "  Page 108 scraped with 20 listings.\n",
      "  Page 109 scraped with 20 listings.\n",
      "  Page 110 scraped with 20 listings.\n",
      "  Page 111 scraped with 20 listings.\n",
      "  Page 112 scraped with 20 listings.\n",
      "  Page 113 scraped with 20 listings.\n",
      "  Page 114 scraped with 20 listings.\n",
      "  Page 115 scraped with 20 listings.\n",
      "  Page 116 scraped with 20 listings.\n",
      "  Page 117 scraped with 20 listings.\n",
      "  Page 118 scraped with 20 listings.\n",
      "  Page 119 scraped with 20 listings.\n",
      "  Page 120 scraped with 20 listings.\n",
      "  Page 121 scraped with 20 listings.\n",
      "  Page 122 scraped with 20 listings.\n",
      "  Page 123 scraped with 20 listings.\n",
      "  Page 124 scraped with 20 listings.\n",
      "  Page 125 scraped with 20 listings.\n",
      "  Page 126 scraped with 20 listings.\n",
      "  Page 127 scraped with 20 listings.\n",
      "  Page 128 scraped with 20 listings.\n",
      "  Page 129 scraped with 20 listings.\n",
      "  Page 130 scraped with 20 listings.\n",
      "  Page 131 scraped with 20 listings.\n",
      "  Page 132 scraped with 20 listings.\n",
      "  Page 133 scraped with 20 listings.\n",
      "  Page 134 scraped with 20 listings.\n",
      "  Page 135 scraped with 20 listings.\n",
      "  Page 136 scraped with 20 listings.\n",
      "  Page 137 scraped with 20 listings.\n",
      "  Page 138 scraped with 20 listings.\n",
      "  Page 139 scraped with 20 listings.\n",
      "  Page 140 scraped with 20 listings.\n",
      "  Page 141 scraped with 20 listings.\n",
      "  Page 142 scraped with 20 listings.\n",
      "  Page 143 scraped with 20 listings.\n",
      "  Page 144 scraped with 20 listings.\n",
      "  Page 145 scraped with 20 listings.\n",
      "  Page 146 scraped with 20 listings.\n",
      "  Page 147 scraped with 20 listings.\n",
      "  Page 148 scraped with 20 listings.\n",
      "  Page 149 scraped with 20 listings.\n",
      "  Page 150 scraped with 20 listings.\n",
      "  Page 151 scraped with 20 listings.\n",
      "  Page 152 scraped with 20 listings.\n",
      "  Page 153 scraped with 20 listings.\n",
      "  Page 154 scraped with 20 listings.\n",
      "  Page 155 scraped with 20 listings.\n",
      "  Page 156 scraped with 20 listings.\n",
      "  Page 157 scraped with 20 listings.\n",
      "  Page 158 scraped with 20 listings.\n",
      "  Page 159 scraped with 20 listings.\n",
      "  Page 160 scraped with 20 listings.\n",
      "  Error on page 161: Message: timeout: Timed out receiving message from renderer: 298.279\n",
      "  (Session info: chrome=136.0.7103.92)\n",
      "Stacktrace:\n",
      "#0 0x5574b5deabee <unknown>\n",
      "#1 0x5574b58a7bcb <unknown>\n",
      "#2 0x5574b58933c6 <unknown>\n",
      "#3 0x5574b589317c <unknown>\n",
      "#4 0x5574b58916c8 <unknown>\n",
      "#5 0x5574b5891b79 <unknown>\n",
      "#6 0x5574b589f220 <unknown>\n",
      "#7 0x5574b58b55bf <unknown>\n",
      "#8 0x5574b58bab0b <unknown>\n",
      "#9 0x5574b58920ed <unknown>\n",
      "#10 0x5574b58b53b7 <unknown>\n",
      "#11 0x5574b593d0ec <unknown>\n",
      "#12 0x5574b591ba73 <unknown>\n",
      "#13 0x5574b58e5d19 <unknown>\n",
      "#14 0x5574b58e6ac8 <unknown>\n",
      "#15 0x5574b5db756a <unknown>\n",
      "#16 0x5574b5dba9be <unknown>\n",
      "#17 0x5574b5dba468 <unknown>\n",
      "#18 0x5574b5dbae45 <unknown>\n",
      "#19 0x5574b5da0cdb <unknown>\n",
      "#20 0x5574b5dbb1b0 <unknown>\n",
      "#21 0x5574b5d89c49 <unknown>\n",
      "#22 0x5574b5dd9f55 <unknown>\n",
      "#23 0x5574b5dda13b <unknown>\n",
      "#24 0x5574b5de9d65 <unknown>\n",
      "#25 0x7fa440ca81f5 <unknown>\n",
      ". Continuing...\n",
      "  Page 162 scraped with 20 listings.\n",
      "  Page 163 scraped with 20 listings.\n",
      "  Page 164 scraped with 20 listings.\n",
      "  Page 165 scraped with 20 listings.\n",
      "  Page 166 scraped with 20 listings.\n",
      "  Page 167 scraped with 20 listings.\n",
      "  Page 168 scraped with 20 listings.\n",
      "  Page 169 scraped with 20 listings.\n",
      "  Page 170 scraped with 20 listings.\n",
      "  Page 171 scraped with 20 listings.\n",
      "  Page 172 scraped with 20 listings.\n",
      "  Page 173 scraped with 20 listings.\n",
      "  Page 174 scraped with 20 listings.\n",
      "  Page 175 scraped with 20 listings.\n",
      "  Page 176 scraped with 20 listings.\n",
      "  Page 177 scraped with 20 listings.\n",
      "  Page 178 scraped with 20 listings.\n",
      "  Page 179 scraped with 20 listings.\n",
      "  Page 180 scraped with 20 listings.\n",
      "  Page 181 scraped with 20 listings.\n",
      "  Page 182 scraped with 20 listings.\n",
      "  Page 183 scraped with 20 listings.\n",
      "  Page 184 scraped with 20 listings.\n",
      "  Page 185 scraped with 20 listings.\n",
      "  Page 186 scraped with 20 listings.\n",
      "  Page 187 scraped with 20 listings.\n",
      "  Page 188 scraped with 20 listings.\n",
      "  Page 189 scraped with 20 listings.\n",
      "  Page 190 scraped with 20 listings.\n",
      "  Page 191 scraped with 20 listings.\n",
      "  Page 192 scraped with 20 listings.\n",
      "  Page 193 scraped with 20 listings.\n",
      "  Page 194 scraped with 20 listings.\n",
      "  Page 195 scraped with 20 listings.\n",
      "  Page 196 scraped with 20 listings.\n",
      "  Page 197 scraped with 20 listings.\n",
      "  Page 198 scraped with 20 listings.\n",
      "  Page 199 scraped with 20 listings.\n",
      "  Page 200 scraped with 20 listings.\n",
      "  Page 201 scraped with 20 listings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Page 202 scraped with 20 listings.\n",
      "  Page 203 scraped with 20 listings.\n",
      "  Page 204 scraped with 20 listings.\n",
      "  Page 205 scraped with 20 listings.\n",
      "  Page 206 scraped with 20 listings.\n",
      "  Page 207 scraped with 20 listings.\n",
      "  Page 208 scraped with 20 listings.\n",
      "  Page 209 scraped with 20 listings.\n",
      "  Page 210 scraped with 20 listings.\n",
      "  Page 211 scraped with 20 listings.\n",
      "  Page 212 scraped with 20 listings.\n",
      "  Page 213 scraped with 20 listings.\n",
      "  Page 214 scraped with 20 listings.\n",
      "  Page 215 scraped with 20 listings.\n",
      "  Page 216 scraped with 20 listings.\n",
      "  Page 217 scraped with 20 listings.\n",
      "  Page 218 scraped with 20 listings.\n",
      "  Page 219 scraped with 20 listings.\n",
      "  Page 220 scraped with 20 listings.\n",
      "  Page 221 scraped with 20 listings.\n",
      "  Page 222 scraped with 20 listings.\n",
      "  Page 223 scraped with 20 listings.\n",
      "  Page 224 scraped with 20 listings.\n",
      "  Page 225 scraped with 20 listings.\n",
      "  Page 226 scraped with 20 listings.\n",
      "  Page 227 scraped with 20 listings.\n",
      "  Page 228 scraped with 20 listings.\n",
      "  Page 229 scraped with 20 listings.\n",
      "  Page 230 scraped with 20 listings.\n",
      "  Page 231 scraped with 20 listings.\n",
      "  Page 232 scraped with 20 listings.\n",
      "  Page 233 scraped with 20 listings.\n",
      "  Page 234 scraped with 20 listings.\n",
      "  Page 235 scraped with 20 listings.\n",
      "  Page 236 scraped with 20 listings.\n",
      "  Page 237 scraped with 20 listings.\n",
      "  Page 238 scraped with 20 listings.\n",
      "  Page 239 scraped with 20 listings.\n",
      "  Page 240 scraped with 20 listings.\n",
      "  Page 241 scraped with 20 listings.\n",
      "  Page 242 scraped with 20 listings.\n",
      "  Page 243 scraped with 20 listings.\n",
      "  Page 244 scraped with 20 listings.\n",
      "  Page 245 scraped with 20 listings.\n",
      "  Page 246 scraped with 20 listings.\n",
      "  Page 247 scraped with 20 listings.\n",
      "  Page 248 scraped with 20 listings.\n",
      "  Page 249 scraped with 20 listings.\n",
      "  Page 250 scraped with 20 listings.\n",
      "  Page 251 scraped with 20 listings.\n",
      "  Page 252 scraped with 20 listings.\n",
      "  Page 253 scraped with 20 listings.\n",
      "  Page 254 scraped with 20 listings.\n",
      "  Page 255 scraped with 20 listings.\n",
      "  Page 256 scraped with 20 listings.\n",
      "  Page 257 scraped with 20 listings.\n",
      "  Page 258 scraped with 20 listings.\n",
      "  Page 259 scraped with 20 listings.\n",
      "  Page 260 scraped with 20 listings.\n",
      "  Page 261 scraped with 20 listings.\n",
      "  Page 262 scraped with 20 listings.\n",
      "  Page 263 scraped with 20 listings.\n",
      "  Page 264 scraped with 20 listings.\n",
      "  Page 265 scraped with 20 listings.\n",
      "  Page 266 scraped with 20 listings.\n",
      "  Page 267 scraped with 20 listings.\n",
      "  Page 268 scraped with 20 listings.\n",
      "  Page 269 scraped with 20 listings.\n",
      "  Page 270 scraped with 20 listings.\n",
      "  Page 271 scraped with 20 listings.\n",
      "  Page 272 scraped with 20 listings.\n",
      "  Page 273 scraped with 20 listings.\n",
      "  Page 274 scraped with 20 listings.\n",
      "  Page 275 scraped with 20 listings.\n",
      "  Page 276 scraped with 20 listings.\n",
      "  Page 277 scraped with 20 listings.\n",
      "  Page 278 scraped with 20 listings.\n",
      "  Page 279 scraped with 20 listings.\n",
      "  Page 280 scraped with 20 listings.\n",
      "  Page 281 scraped with 20 listings.\n",
      "  Page 282 scraped with 20 listings.\n",
      "  Page 283 scraped with 20 listings.\n",
      "  Page 284 scraped with 20 listings.\n",
      "  Page 285 scraped with 20 listings.\n",
      "  Page 286 scraped with 20 listings.\n",
      "  Page 287 scraped with 20 listings.\n",
      "  Page 288 scraped with 20 listings.\n",
      "  Page 289 scraped with 20 listings.\n",
      "  Page 290 scraped with 20 listings.\n",
      "  Page 291 scraped with 20 listings.\n",
      "  Page 292 scraped with 20 listings.\n",
      "  Page 293 scraped with 20 listings.\n",
      "  Page 294 scraped with 20 listings.\n",
      "  Page 295 scraped with 20 listings.\n",
      "  Page 296 scraped with 20 listings.\n",
      "  Page 297 scraped with 20 listings.\n",
      "  Page 298 scraped with 20 listings.\n",
      "  Page 299 scraped with 20 listings.\n",
      "  Page 300 scraped with 20 listings.\n",
      "  Page 301 scraped with 20 listings.\n",
      "  Page 302 scraped with 20 listings.\n",
      "  Page 303 scraped with 20 listings.\n",
      "  Page 304 scraped with 20 listings.\n",
      "  Page 305 scraped with 20 listings.\n",
      "  Page 306 scraped with 20 listings.\n",
      "  Page 307 scraped with 20 listings.\n",
      "  Page 308 scraped with 20 listings.\n",
      "  Page 309 scraped with 20 listings.\n",
      "  Page 310 scraped with 20 listings.\n",
      "  Page 311 scraped with 20 listings.\n",
      "  Page 312 scraped with 20 listings.\n",
      "  Page 313 scraped with 20 listings.\n",
      "  Page 314 scraped with 20 listings.\n",
      "  Page 315 scraped with 20 listings.\n",
      "  Page 316 scraped with 20 listings.\n",
      "  Page 317 scraped with 20 listings.\n",
      "  Page 318 scraped with 20 listings.\n",
      "  Page 319 scraped with 20 listings.\n",
      "  Page 320 scraped with 20 listings.\n",
      "  Page 321 scraped with 20 listings.\n",
      "  Page 322 scraped with 20 listings.\n",
      "  Page 323 scraped with 20 listings.\n",
      "  Page 324 scraped with 20 listings.\n",
      "  Page 325 scraped with 20 listings.\n",
      "  Page 326 scraped with 20 listings.\n",
      "  Page 327 scraped with 20 listings.\n",
      "  Page 328 scraped with 20 listings.\n",
      "  Page 329 scraped with 20 listings.\n",
      "  Page 330 scraped with 20 listings.\n",
      "  Page 331 scraped with 20 listings.\n",
      "  Page 332 scraped with 20 listings.\n",
      "  Page 333 scraped with 20 listings.\n",
      "  Page 334 scraped with 20 listings.\n",
      "  Page 335 scraped with 20 listings.\n",
      "  Page 336 scraped with 20 listings.\n",
      "  Page 337 scraped with 20 listings.\n",
      "  Page 338 scraped with 20 listings.\n",
      "  Page 339 scraped with 20 listings.\n",
      "  Page 340 scraped with 20 listings.\n",
      "  Page 341 scraped with 20 listings.\n",
      "  Page 342 scraped with 20 listings.\n",
      "  Page 343 scraped with 20 listings.\n",
      "  Page 344 scraped with 20 listings.\n",
      "  Page 345 scraped with 20 listings.\n",
      "  Page 346 scraped with 20 listings.\n",
      "  Page 347 scraped with 20 listings.\n",
      "  Page 348 scraped with 20 listings.\n",
      "  Page 349 scraped with 20 listings.\n",
      "  Page 350 scraped with 20 listings.\n",
      "  Page 351 scraped with 20 listings.\n",
      "  Page 352 scraped with 20 listings.\n",
      "  Page 353 scraped with 20 listings.\n",
      "  Page 354 scraped with 20 listings.\n",
      "  Page 355 scraped with 20 listings.\n",
      "  Page 356 scraped with 20 listings.\n",
      "  Page 357 scraped with 20 listings.\n",
      "  Page 358 scraped with 20 listings.\n",
      "  Page 359 scraped with 20 listings.\n",
      "  Page 360 scraped with 20 listings.\n",
      "  Page 361 scraped with 20 listings.\n",
      "  Page 362 scraped with 20 listings.\n",
      "  Page 363 scraped with 20 listings.\n",
      "  Page 364 scraped with 20 listings.\n",
      "  Page 365 scraped with 20 listings.\n",
      "  Page 366 scraped with 20 listings.\n",
      "  Page 367 scraped with 20 listings.\n",
      "  Page 368 scraped with 20 listings.\n",
      "  Page 369 scraped with 20 listings.\n",
      "  Page 370 scraped with 20 listings.\n",
      "  Page 371 scraped with 20 listings.\n",
      "  Page 372 scraped with 20 listings.\n",
      "  Page 373 scraped with 20 listings.\n",
      "  Page 374 scraped with 20 listings.\n",
      "  Page 375 scraped with 20 listings.\n",
      "  Page 376 scraped with 20 listings.\n",
      "  Page 377 scraped with 20 listings.\n",
      "  Page 378 scraped with 20 listings.\n",
      "  Page 379 scraped with 20 listings.\n",
      "  Page 380 scraped with 20 listings.\n",
      "  Page 381 scraped with 20 listings.\n",
      "  Page 382 scraped with 20 listings.\n",
      "  Page 383 scraped with 20 listings.\n",
      "  Page 384 scraped with 20 listings.\n",
      "  Page 385 scraped with 20 listings.\n",
      "  Page 386 scraped with 20 listings.\n",
      "  Page 387 scraped with 20 listings.\n",
      "  Page 388 scraped with 20 listings.\n",
      "  Page 389 scraped with 20 listings.\n",
      "  Page 390 scraped with 20 listings.\n",
      "  Page 391 scraped with 20 listings.\n",
      "  Page 392 scraped with 20 listings.\n",
      "  Page 393 scraped with 20 listings.\n",
      "  Page 394 scraped with 20 listings.\n",
      "  Page 395 scraped with 20 listings.\n",
      "  Page 396 scraped with 20 listings.\n",
      "  Page 397 scraped with 20 listings.\n",
      "  Page 398 scraped with 20 listings.\n",
      "  Page 399 scraped with 20 listings.\n",
      "  Page 400 scraped with 20 listings.\n",
      "  Page 401 scraped with 20 listings.\n",
      "  Page 402 scraped with 20 listings.\n",
      "  Page 403 scraped with 20 listings.\n",
      "  Page 404 scraped with 20 listings.\n",
      "  Page 405 scraped with 20 listings.\n",
      "  Page 406 scraped with 20 listings.\n",
      "  Page 407 scraped with 20 listings.\n",
      "  Page 408 scraped with 20 listings.\n",
      "  Page 409 scraped with 20 listings.\n",
      "  Page 410 scraped with 20 listings.\n",
      "  Page 411 scraped with 20 listings.\n",
      "  Page 412 scraped with 20 listings.\n",
      "  Page 413 scraped with 20 listings.\n",
      "  Page 414 scraped with 20 listings.\n",
      "  Page 415 scraped with 20 listings.\n",
      "  Page 416 scraped with 20 listings.\n",
      "  Page 417 scraped with 20 listings.\n",
      "  Page 418 scraped with 20 listings.\n",
      "  Page 419 scraped with 20 listings.\n",
      "  Error on page 420: Message: timeout: Timed out receiving message from renderer: 299.129\n",
      "  (Session info: chrome=136.0.7103.92)\n",
      "Stacktrace:\n",
      "#0 0x5574b5deabee <unknown>\n",
      "#1 0x5574b58a7bcb <unknown>\n",
      "#2 0x5574b58933c6 <unknown>\n",
      "#3 0x5574b589317c <unknown>\n",
      "#4 0x5574b58916c8 <unknown>\n",
      "#5 0x5574b5891b79 <unknown>\n",
      "#6 0x5574b589f220 <unknown>\n",
      "#7 0x5574b58b55bf <unknown>\n",
      "#8 0x5574b58bab0b <unknown>\n",
      "#9 0x5574b58920ed <unknown>\n",
      "#10 0x5574b58b53b7 <unknown>\n",
      "#11 0x5574b593d0ec <unknown>\n",
      "#12 0x5574b591ba73 <unknown>\n",
      "#13 0x5574b58e5d19 <unknown>\n",
      "#14 0x5574b58e6ac8 <unknown>\n",
      "#15 0x5574b5db756a <unknown>\n",
      "#16 0x5574b5dba9be <unknown>\n",
      "#17 0x5574b5dba468 <unknown>\n",
      "#18 0x5574b5dbae45 <unknown>\n",
      "#19 0x5574b5da0cdb <unknown>\n",
      "#20 0x5574b5dbb1b0 <unknown>\n",
      "#21 0x5574b5d89c49 <unknown>\n",
      "#22 0x5574b5dd9f55 <unknown>\n",
      "#23 0x5574b5dda13b <unknown>\n",
      "#24 0x5574b5de9d65 <unknown>\n",
      "#25 0x7fa440ca81f5 <unknown>\n",
      ". Continuing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Page 421 scraped with 20 listings.\n",
      "  Page 422 scraped with 20 listings.\n",
      "  Page 423 scraped with 20 listings.\n",
      "  Page 424 scraped with 20 listings.\n",
      "  Page 425 scraped with 20 listings.\n",
      "  Page 426 scraped with 20 listings.\n",
      "  Page 427 scraped with 20 listings.\n",
      "  Page 428 scraped with 20 listings.\n",
      "  Page 429 scraped with 20 listings.\n",
      "  Page 430 scraped with 20 listings.\n",
      "  Page 431 scraped with 20 listings.\n",
      "  Page 432 scraped with 20 listings.\n",
      "  Page 433 scraped with 20 listings.\n",
      "  Page 434 scraped with 20 listings.\n",
      "  Page 435 scraped with 20 listings.\n",
      "  Page 436 scraped with 20 listings.\n",
      "  Page 437 scraped with 20 listings.\n",
      "  Page 438 scraped with 20 listings.\n",
      "  Page 439 scraped with 20 listings.\n",
      "  Page 440 scraped with 20 listings.\n",
      "  Page 441 scraped with 20 listings.\n",
      "  Page 442 scraped with 20 listings.\n",
      "  Page 443 scraped with 20 listings.\n",
      "  Page 444 scraped with 20 listings.\n",
      "  Page 445 scraped with 20 listings.\n",
      "  Page 446 scraped with 20 listings.\n",
      "  Page 447 scraped with 20 listings.\n",
      "  Page 448 scraped with 20 listings.\n",
      "  Page 449 scraped with 20 listings.\n",
      "  Page 450 scraped with 20 listings.\n",
      "  Page 451 scraped with 20 listings.\n",
      "  Page 452 scraped with 20 listings.\n",
      "  Page 453 scraped with 20 listings.\n",
      "  Page 454 scraped with 20 listings.\n",
      "  Page 455 scraped with 20 listings.\n",
      "  Page 456 scraped with 20 listings.\n",
      "  Page 457 scraped with 20 listings.\n",
      "  Page 458 scraped with 20 listings.\n",
      "  Page 459 scraped with 20 listings.\n",
      "  Page 460 scraped with 20 listings.\n",
      "  Page 461 scraped with 20 listings.\n",
      "  Page 462 scraped with 20 listings.\n",
      "  Page 463 scraped with 20 listings.\n",
      "  Page 464 scraped with 20 listings.\n",
      "  Page 465 scraped with 20 listings.\n",
      "  Page 466 scraped with 20 listings.\n",
      "  Page 467 scraped with 20 listings.\n",
      "  Page 468 scraped with 20 listings.\n",
      "  Page 469 scraped with 20 listings.\n",
      "  Page 470 scraped with 20 listings.\n",
      "  Page 471 scraped with 20 listings.\n",
      "  Page 472 scraped with 20 listings.\n",
      "  Page 473 scraped with 20 listings.\n",
      "  Page 474 scraped with 20 listings.\n",
      "  Page 475 scraped with 20 listings.\n",
      "  Page 476 scraped with 20 listings.\n",
      "  Page 477 scraped with 20 listings.\n",
      "  Page 478 scraped with 20 listings.\n",
      "  Page 479 scraped with 20 listings.\n",
      "  Page 480 scraped with 20 listings.\n",
      "  Page 481 scraped with 20 listings.\n",
      "  Page 482 scraped with 20 listings.\n",
      "  Page 483 scraped with 20 listings.\n",
      "  Page 484 scraped with 20 listings.\n",
      "  Page 485 scraped with 20 listings.\n",
      "  Page 486 scraped with 20 listings.\n",
      "  Page 487 scraped with 20 listings.\n",
      "  Page 488 scraped with 20 listings.\n",
      "  Page 489 scraped with 20 listings.\n",
      "  Page 490 scraped with 20 listings.\n",
      "  Page 491 scraped with 20 listings.\n",
      "  Page 492 scraped with 20 listings.\n",
      "  Page 493 scraped with 20 listings.\n",
      "  Page 494 scraped with 20 listings.\n",
      "  Page 495 scraped with 20 listings.\n",
      "  Page 496 scraped with 20 listings.\n",
      "  Page 497 scraped with 20 listings.\n",
      "  Page 498 scraped with 20 listings.\n",
      "  Page 499 scraped with 20 listings.\n",
      "  Page 500 scraped with 20 listings.\n",
      "  Page 501 scraped with 20 listings.\n",
      "  Page 502 scraped with 20 listings.\n",
      "  Page 503 scraped with 20 listings.\n",
      "  Page 504 scraped with 20 listings.\n",
      "  Page 505 scraped with 20 listings.\n",
      "  Page 506 scraped with 20 listings.\n",
      "  Page 507 scraped with 20 listings.\n",
      "  Page 508 scraped with 20 listings.\n",
      "  Page 509 scraped with 20 listings.\n",
      "  Page 510 scraped with 20 listings.\n",
      "  Page 511 scraped with 20 listings.\n",
      "  Page 512 scraped with 20 listings.\n",
      "  Page 513 scraped with 20 listings.\n",
      "  Page 514 scraped with 20 listings.\n",
      "  Page 515 scraped with 20 listings.\n",
      "  Page 516 scraped with 20 listings.\n",
      "  Page 517 scraped with 20 listings.\n",
      "  Page 518 scraped with 20 listings.\n",
      "  Page 519 scraped with 20 listings.\n",
      "  Page 520 scraped with 20 listings.\n",
      "  Page 521 scraped with 20 listings.\n",
      "  Page 522 scraped with 20 listings.\n",
      "  Page 523 scraped with 20 listings.\n",
      "  Page 524 scraped with 20 listings.\n",
      "  Page 525 scraped with 20 listings.\n",
      "  Page 526 scraped with 20 listings.\n",
      "  Page 527 scraped with 20 listings.\n",
      "  Page 528 scraped with 20 listings.\n",
      "  Page 529 scraped with 20 listings.\n",
      "  Page 530 scraped with 20 listings.\n",
      "  Page 531 scraped with 20 listings.\n",
      "  Page 532 scraped with 20 listings.\n",
      "  Page 533 scraped with 20 listings.\n",
      "  Page 534 scraped with 20 listings.\n",
      "  Page 535 scraped with 20 listings.\n",
      "  Page 536 scraped with 20 listings.\n",
      "  Page 537 scraped with 20 listings.\n",
      "  Page 538 scraped with 20 listings.\n",
      "  Page 539 scraped with 20 listings.\n",
      "  Page 540 scraped with 20 listings.\n",
      "  Page 541 scraped with 20 listings.\n",
      "  Page 542 scraped with 20 listings.\n",
      "  Page 543 scraped with 20 listings.\n",
      "  Page 544 scraped with 20 listings.\n",
      "  Page 545 scraped with 20 listings.\n",
      "  Page 546 scraped with 20 listings.\n",
      "  Page 547 scraped with 20 listings.\n",
      "  Page 548 scraped with 20 listings.\n",
      "  Page 549 scraped with 20 listings.\n",
      "  Page 550 scraped with 20 listings.\n",
      "  Page 551 scraped with 20 listings.\n",
      "  Page 552 scraped with 20 listings.\n",
      "  Page 553 scraped with 20 listings.\n",
      "  Page 554 scraped with 20 listings.\n",
      "  Page 555 scraped with 20 listings.\n",
      "  Page 556 scraped with 20 listings.\n",
      "  Page 557 scraped with 20 listings.\n",
      "  Page 558 scraped with 20 listings.\n",
      "  Page 559 scraped with 20 listings.\n",
      "  Page 560 scraped with 20 listings.\n",
      "  Page 561 scraped with 20 listings.\n",
      "  Page 562 scraped with 20 listings.\n",
      "  Page 563 scraped with 20 listings.\n",
      "  Page 564 scraped with 20 listings.\n",
      "  Page 565 scraped with 20 listings.\n",
      "  Page 566 scraped with 20 listings.\n",
      "  Page 567 scraped with 20 listings.\n",
      "  Page 568 scraped with 20 listings.\n",
      "  Page 569 scraped with 20 listings.\n",
      "  Page 570 scraped with 20 listings.\n",
      "  Page 571 scraped with 20 listings.\n",
      "  Page 572 scraped with 20 listings.\n",
      "  Page 573 scraped with 20 listings.\n",
      "  Page 574 scraped with 20 listings.\n",
      "  Page 575 scraped with 20 listings.\n",
      "  Page 576 scraped with 20 listings.\n",
      "  Page 577 scraped with 20 listings.\n",
      "  Page 578 scraped with 20 listings.\n",
      "  Page 579 scraped with 20 listings.\n",
      "  Page 580 scraped with 20 listings.\n",
      "  Page 581 scraped with 20 listings.\n",
      "  Page 582 scraped with 20 listings.\n",
      "  Page 583 scraped with 20 listings.\n",
      "  Page 584 scraped with 20 listings.\n",
      "  Page 585 scraped with 20 listings.\n",
      "  Page 586 scraped with 20 listings.\n",
      "  Page 587 scraped with 20 listings.\n",
      "  Page 588 scraped with 20 listings.\n",
      "  Page 589 scraped with 20 listings.\n",
      "  Page 590 scraped with 20 listings.\n",
      "  Page 591 scraped with 20 listings.\n",
      "  Page 592 scraped with 20 listings.\n",
      "  Page 593 scraped with 20 listings.\n",
      "  Page 594 scraped with 20 listings.\n",
      "  Page 595 scraped with 20 listings.\n",
      "  Page 596 scraped with 20 listings.\n",
      "  Page 597 scraped with 20 listings.\n",
      "  Page 598 scraped with 20 listings.\n",
      "  Page 599 scraped with 20 listings.\n",
      "  Page 600 scraped with 20 listings.\n",
      "  Page 601 scraped with 20 listings.\n",
      "  Page 602 scraped with 20 listings.\n",
      "  Page 603 scraped with 20 listings.\n",
      "  Page 604 scraped with 20 listings.\n",
      "  Page 605 scraped with 20 listings.\n",
      "  Page 606 scraped with 20 listings.\n",
      "  Page 607 scraped with 20 listings.\n",
      "  Page 608 scraped with 20 listings.\n",
      "  Page 609 scraped with 20 listings.\n",
      "  Page 610 scraped with 20 listings.\n",
      "  Page 611 scraped with 20 listings.\n",
      "  Page 612 scraped with 20 listings.\n",
      "  Page 613 scraped with 20 listings.\n",
      "  Page 614 scraped with 20 listings.\n",
      "  Page 615 scraped with 20 listings.\n",
      "  Page 616 scraped with 20 listings.\n",
      "  Page 617 scraped with 20 listings.\n",
      "  Page 618 scraped with 20 listings.\n",
      "  Page 619 scraped with 20 listings.\n",
      "  Page 620 scraped with 20 listings.\n",
      "  Page 621 scraped with 20 listings.\n",
      "  Page 622 scraped with 20 listings.\n",
      "  Page 623 scraped with 20 listings.\n",
      "  Page 624 scraped with 20 listings.\n",
      "  Page 625 scraped with 20 listings.\n",
      "  Page 626 scraped with 20 listings.\n",
      "  Page 627 scraped with 20 listings.\n",
      "  Page 628 scraped with 20 listings.\n",
      "  Page 629 scraped with 20 listings.\n",
      "  Page 630 scraped with 20 listings.\n",
      "  Page 631 scraped with 20 listings.\n",
      "  Page 632 scraped with 20 listings.\n",
      "  Page 633 scraped with 20 listings.\n",
      "  Page 634 scraped with 20 listings.\n",
      "  Page 635 scraped with 20 listings.\n",
      "  Page 636 scraped with 20 listings.\n",
      "  Page 637 scraped with 20 listings.\n",
      "  Page 638 scraped with 20 listings.\n",
      "  Page 639 scraped with 20 listings.\n",
      "  Page 640 scraped with 20 listings.\n",
      "  Page 641 scraped with 20 listings.\n",
      "  Page 642 scraped with 20 listings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Page 643 scraped with 20 listings.\n",
      "  Page 644 scraped with 20 listings.\n",
      "  Page 645 scraped with 20 listings.\n",
      "  Page 646 scraped with 20 listings.\n",
      "  Page 647 scraped with 20 listings.\n",
      "  Page 648 scraped with 20 listings.\n",
      "  Page 649 scraped with 20 listings.\n",
      "  Page 650 scraped with 20 listings.\n",
      "  Page 651 scraped with 20 listings.\n",
      "  Page 652 scraped with 20 listings.\n",
      "  Page 653 scraped with 20 listings.\n",
      "  Page 654 scraped with 20 listings.\n",
      "  Page 655 scraped with 20 listings.\n",
      "  Page 656 scraped with 20 listings.\n",
      "  Page 657 scraped with 20 listings.\n",
      "  Page 658 scraped with 20 listings.\n",
      "  Page 659 scraped with 20 listings.\n",
      "  Page 660 scraped with 20 listings.\n",
      "  Page 661 scraped with 20 listings.\n",
      "  Page 662 scraped with 20 listings.\n",
      "  Page 663 scraped with 20 listings.\n",
      "  Page 664 scraped with 20 listings.\n",
      "  Page 665 scraped with 20 listings.\n",
      "  Page 666 scraped with 20 listings.\n",
      "  Page 667 scraped with 20 listings.\n",
      "  Page 668 scraped with 20 listings.\n",
      "  Page 669 scraped with 20 listings.\n",
      "  Page 670 scraped with 20 listings.\n",
      "  Page 671 scraped with 20 listings.\n",
      "  Page 672 scraped with 20 listings.\n",
      "  Page 673 scraped with 20 listings.\n",
      "  Page 674 scraped with 20 listings.\n",
      "  Page 675 scraped with 20 listings.\n",
      "  Page 676 scraped with 20 listings.\n",
      "  Page 677 scraped with 20 listings.\n",
      "  Page 678 scraped with 20 listings.\n",
      "  Page 679 scraped with 20 listings.\n",
      "  Page 680 scraped with 20 listings.\n",
      "  Page 681 scraped with 20 listings.\n",
      "  Page 682 scraped with 20 listings.\n",
      "  Page 683 scraped with 20 listings.\n",
      "  Page 684 scraped with 20 listings.\n",
      "  Page 685 scraped with 20 listings.\n",
      "  Page 686 scraped with 20 listings.\n",
      "  Page 687 scraped with 20 listings.\n",
      "  Page 688 scraped with 20 listings.\n",
      "  Page 689 scraped with 20 listings.\n",
      "  Page 690 scraped with 20 listings.\n",
      "  Page 691 scraped with 20 listings.\n",
      "  Page 692 scraped with 20 listings.\n",
      "  Page 693 scraped with 20 listings.\n",
      "  Page 694 scraped with 20 listings.\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- STEP 1: Collect all listing URLs ----------\n",
    "def get_listing_urls(driver, fuel_type):\n",
    "    page = 1\n",
    "    all_urls = []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            url = f\"https://avtoelon.uz/uz/avto/?auto-fuel={fuel_type}&page={page}\"\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            buttons = driver.find_elements(By.XPATH, '//button[contains(@class, \"js__advert-button\")]')\n",
    "            if not buttons:\n",
    "                print(f\"  No more listings on page {page}.\")\n",
    "                break\n",
    "\n",
    "            for button in buttons:\n",
    "                partial_url = button.get_attribute('data-url')\n",
    "                if partial_url:\n",
    "                    full_url = f\"https://avtoelon.uz{partial_url}\"\n",
    "                    all_urls.append(full_url)\n",
    "\n",
    "            print(f\"  Page {page} scraped with {len(buttons)} listings.\")\n",
    "            page += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on page {page}: {e}. Continuing...\")\n",
    "            page += 1\n",
    "            continue\n",
    "\n",
    "    return all_urls\n",
    "\n",
    "# ---------- STEP 2: Scrape individual car data ----------\n",
    "def scrape_listing_data(driver, urls):\n",
    "    data = {\n",
    "        \"brands\": [],\n",
    "        \"names\": [],\n",
    "        \"prices\": [],\n",
    "        \"cities\": [],\n",
    "        \"engines\": [],\n",
    "        \"kuzovs\": [],\n",
    "        \"milages\": [],\n",
    "        \"driving_types\": [],\n",
    "        \"colors\": [],\n",
    "        \"paint_info\": [],\n",
    "        \"uzatmalar\": [],\n",
    "        \"negotiations\": [],\n",
    "        \"exteriors\": [],\n",
    "        \"optika\": [],\n",
    "        \"audioes\": [],\n",
    "        \"optsiyalar\": [],\n",
    "        \"additionals\": [],\n",
    "        \"phone_numbers\": [],\n",
    "        \"photos\": []  # Add new column for photos\n",
    "    }\n",
    "\n",
    "    unread_urls = []\n",
    "    \n",
    "    def safe_get_text(xpath):\n",
    "        try:\n",
    "            return driver.find_element(By.XPATH, xpath).text\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    # ---------- STEP 3: Scraping process ----------\n",
    "    for full_url in urls:\n",
    "        print(f\"Scraping: {full_url}\")\n",
    "        driver.get(full_url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        # Step 1: Try to fetch phone number first\n",
    "        try:\n",
    "            phone_button = driver.find_element(By.XPATH, '//div[contains(@class, \"phone\")]//ul')\n",
    "            phone_button.click()\n",
    "            time.sleep(3)\n",
    "            result[\"phone\"] = phone_button.text\n",
    "        except:\n",
    "            result[\"phone\"] = \"\"\n",
    "            unread_urls.append(full_url)\n",
    "            continue  # Skip the rest of the scraping for this listing if no phone number\n",
    "\n",
    "        # Step 2: If phone number is found, proceed with scraping other data\n",
    "        result[\"brand\"] = safe_get_text('//header//h1/span[1]')\n",
    "        result[\"name\"] = safe_get_text('//header//h1/span[2]')\n",
    "        result[\"price\"] = safe_get_text('//header/div[2]')\n",
    "        result[\"city\"] = safe_get_text('//section/div/div[1]/div[1]/div/dl/dd[1]')\n",
    "        result[\"engine\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[3]')\n",
    "        result[\"kuzov\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[4]')\n",
    "        result[\"milage\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[5]')\n",
    "        result[\"driving_type\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[6]')\n",
    "        result[\"color\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[7]')\n",
    "        result[\"paint_info\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[8]')\n",
    "        result[\"uzatma\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[9]')\n",
    "        result[\"negotiation\"] = safe_get_text('//section/div/div[2]/div[1]/div/dl/dd[10]')\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.ID, \"js-params-block\").click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        result[\"exterior\"] = safe_get_text('//*[@id=\"js-params-block\"]/ul/li[1]')\n",
    "        result[\"optika\"] = safe_get_text('//*[@id=\"js-params-block\"]/ul/li[2]')\n",
    "        result[\"audio\"] = safe_get_text('//*[@id=\"js-params-block\"]/ul/li[3]')\n",
    "        result[\"optsiyalar\"] = safe_get_text('//*[@id=\"js-params-block\"]/ul/li[4]')\n",
    "        result[\"additional\"] = safe_get_text('//*[@id=\"js-params-block\"]/ul/li[5]')\n",
    "\n",
    "        # ---------- Step 3.1: Scrape photos ----------\n",
    "        try:\n",
    "            photo_elements = driver.find_elements(By.XPATH, '/html/body/div[1]/div[1]/main/div/div/section/div/div[1]/div[2]/ul/li/img')\n",
    "            photos = [photo.get_attribute('src') for photo in photo_elements]\n",
    "            result[\"photos\"] = \"; \".join(photos)  # Join all photo URLs with semicolon\n",
    "        except:\n",
    "            result[\"photos\"] = \"\"\n",
    "\n",
    "        # Add phone number only if it exists\n",
    "        data[\"phone_numbers\"].append(result[\"phone\"])\n",
    "\n",
    "        # Append other data\n",
    "        for key in data:\n",
    "            if key != \"phone_numbers\":\n",
    "                col = key if key != \"phone_numbers\" else \"phone\"\n",
    "                data[key].append(result.get(col, \"\"))\n",
    "\n",
    "    # ---------- STEP 4: Retry logic for missing phone numbers ----------\n",
    "    retries = 5\n",
    "    attempt = 0\n",
    "    while attempt < retries and unread_urls:\n",
    "        print(f\"Retrying phone numbers... Attempt {attempt + 1}/{retries}\")\n",
    "        new_unread_urls = []\n",
    "\n",
    "        for url in unread_urls:\n",
    "            print(f\"Retrying: {url}\")\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            try:\n",
    "                phone_button = driver.find_element(By.XPATH, '//div[contains(@class, \"phone\")]//ul')\n",
    "                phone_button.click()\n",
    "                time.sleep(1)\n",
    "                phone_number = phone_button.text\n",
    "                data[\"phone_numbers\"].append(phone_number)\n",
    "            except:\n",
    "                new_unread_urls.append(url)\n",
    "\n",
    "        unread_urls = new_unread_urls\n",
    "        attempt += 1\n",
    "        time.sleep(40)\n",
    "\n",
    "    print(f\"Finished retrying. Ignored {len(unread_urls)} listings with missing phone numbers.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    service = Service()\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    fuel_type = 1  # Change this as needed\n",
    "    urls = get_listing_urls(driver, fuel_type)\n",
    "    print(f\"Collected {len(urls)} listing URLs.\")\n",
    "\n",
    "    scraped_data = scrape_listing_data(driver, urls)\n",
    "\n",
    "    df = pd.DataFrame(scraped_data)\n",
    "    df.to_csv(\"scraped_car_data.csv\", index=False)\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "# just a quick note i have mistakenly quited the driver and now\n",
    "# since i have the urls' like saved i can definately use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60f158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e89ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644a944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e328510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e0486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
